[
    {
        "title": "A hackable AI assistant using a single SQLite table and a handful of cron jobs",
        "url": "https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs",
        "content": "Geoffrey Litt Projects Writing Inspirations Subscribe: Newsletter Twitter Mastodon RSS Contact Email me April 2025 Stevens: a hackable AI assistant using a single SQLite table and a handful of cron jobs There\u2019s a lot of hype these days around patterns for building with AI. Agents, memory, RAG, assistants\u2014so many buzzwords! But the reality is, you don\u2019t need fancy techniques or libraries to build useful personal tools with LLMs. In this short post, I\u2019ll show you how I built a useful AI assistant for my family using a dead simple architecture: a single SQLite table of memories, and a handful of cron jobs for ingesting memories and sending updates, all hosted on Val.town. The whole thing is so simple that you can easily copy and extend it yourself. Meet Stevens The assistant is called Stevens, named after the butler in the great Ishiguro novel Remains of the Day. Every morning it sends a brief to me and my wife via Telegram, including our calendar schedules for the day, a preview of the weather forecast, any postal mail or packages we\u2019re expected to receive, and any reminders we\u2019ve asked it to keep track of. All written up nice and formally, just like you\u2019d expect from a proper butler. Here\u2019s an example. (I\u2019ll use fake data throughout this post, beacuse our actual updates contain private information.) Beyond the daily brief, we can communicate with Stevens on-demand\u2014we can forward an email with some important info, or just leave a reminder or ask a question via Telegram chat. That\u2019s Stevens. It\u2019s rudimentary, but already more useful to me than Siri! Behind the scenes Let\u2019s break down the simple architecture behind Stevens. The whole thing is hosted on Val.town, a lovely platform that offers SQLite storage, HTTP request handling, scheduled cron jobs, and inbound/outbound email: a perfect set of capabilities for this project. First, how does Stevens know what goes in the morning brief? The key is the butler\u2019s notebook, a log of everything that Stevens knows. There\u2019s an admin view where we can see the notebook contents\u2014let\u2019s peek and see what\u2019s in there: You can see some of the entries that fed into the morning brief above\u2014for example, the parent-teacher conference has a log entry. In addition to some text, entries can have a date when they are expected to be relevant. There are also entries with no date that serve as general background info, and are always included. You can see these particular background memories came from a Telegram chat, because Stevens does an intake interview via Telegram when you first get started: With this notebook in hand, sending the morning brief is easy: just run a cron job which makes a call to the Claude API to write the update, and then sends the text to a Telegram thread. As context for the model, we include any log entries dated for the coming week, as well as the undated background entries. Under the hood, the \u201cnotebook\u201d is just a single SQLite table with a few columns. Here\u2019s a more boring view of things: But wait: how did the various log entries get there in the first place? In the admin view, we can watch Stevens buzzing around entering things into the log from various sources: This is just some data importers populating the table: An hourly data pull from the Google Calendar API An hourly check of the local weather forecast using a weather API I forward USPS Informed Delivery containing scans of our postal mail, and Stevens OCRs them using Claude Inbound Telegram and email messages can also result in log entries Every week, some \u201cfun facts\u201d get added into the log, as a way of adding some color to future daily updates. This system is easily extensible with new importers. An importer is just any process that adds/edits memories in the log. The memory contents can be any arbitrary text, since they\u2019ll just be fed back into an LLM later anyways. Reflections A few quick reflections on this project: It\u2019s very useful for personal AI tools to have access to broader context from other information sources. Awareness of things like my calendar and the weather forecast turns a dumb chatbot into a useful assistant. ChatGPT recently added memory of past conversations, but there\u2019s lots of information not stored within that silo. I\u2019ve written before about how the endgame for AI-driven personal software isn\u2019t more app silos, it\u2019s small tools operating on a shared pool of context about our lives. \u201cMemory\u201d can start simple. In this case, the use cases of the assistant are limited, and its information is inherently time-bounded, so it\u2019s fairly easy to query for the relevant context to give to the LLM. It also helps that some modern models have long context windows. As the available information grows in size, RAG and fancier approaches to memory may be needed, but you can start simple. Vibe coding enables sillier projects. Initially, Stevens spoke with a dry tone, like you might expect from a generic Apple or Google product. But it turned out it was just more fun to have the assistant speak like a formal butler. This was trivial to do, just a couple lines in a prompt. Similarly, I decided to make the admin dashboard views feel like a video game, because why not? I generated the image assets in ChatGPT, and vibe coded the whole UI in Cursor + Claude 3.7 Sonnet; it took a tiny bit of extra effort in exchange for a lot more fun. Try it yourself Stevens isn\u2019t a product you can run out of the box, it\u2019s just a personal project I made for myself. But if you\u2019re curious, you can check out the code and fork the project here. You should be able to apply this basic pattern\u2014a single memories table and an extensible constellation of cron jobs\u2014to do lots of other useful things. I recommend editing the code using your AI editor of choice with the Val Town CLI to sync to local filesystem. Subscribe I periodically write about programming tools, end-user programming, and other software topics. To get updates about new posts: Join my email newsletter Follow me on Twitter Subscribe via RSS",
        "headline": "Introduction of Stevens, a simple AI assistant",
        "entry_sentence": "Geoffrey Litt has created an AI assistant named Stevens using a single SQLite table and cron jobs.",
        "detail": "Stevens sends daily updates to his family, including weather forecasts and calendar schedules, making it a practical tool for organizing their day.",
        "icon": "\ud83d\udfe3"
    },
    {
        "title": "The path to open-sourcing the DeepSeek inference engine",
        "url": "https://github.com/deepseek-ai/open-infra-index/tree/main/OpenSourcing_DeepSeek_Inference_Engine",
        "content": "Skip to content Navigation Menu Product Solutions Resources Open Source Enterprise Pricing Sign in Sign up deepseek-ai / open-infra-index Public Notifications Fork 259 Star 7.5k Code Pull requests Discussions Actions Projects Security Insights Files main 202502OpenSourceWeek OpenSourcing_DeepSeek_Inference_Engine README.md LICENSE README.md Breadcrumbs open-infra-index /OpenSourcing_DeepSeek_Inference_Engine/ Directory actions More options Latest commit hnyls2002 \u91cd\u547d\u540dDeepseek\u5f00\u6e90\u63a8\u7406\u5f15\u64ce\uff0c\u6d88\u9664\u6b67\u4e49 4a95a9d \u00b7 History History Folders and files Name Last commit message Last commit date parent directory .. README.md \u91cd\u547d\u540dDeepseek\u5f00\u6e90\u63a8\u7406\u5f15\u64ce\uff0c\u6d88\u9664\u6b67\u4e49 README.md The Path to Open-Sourcing the DeepSeek Inference Engine A few weeks ago, during Open Source Week, we open-sourced several libraries. The response from the community has been incredibly positive - sparking inspiring collaborations, productive discussions, and valuable bug fixes. Encouraged by this, we\u2019ve decided to take another step forward: contributing our internal inference engine back to the open-source community. We are deeply grateful for the open-source ecosystem, without which our progress toward AGI would not be possible. Our training framework relies on PyTorch, and our inference engine is built upon vLLM, both of which have been instrumental in accelerating the training and deployment of DeepSeek models. Given the growing demand for deploying models like DeepSeek-V3 and DeepSeek-R1, we want to give back to the community as much as we can. While we initially considered open-sourcing our full internal inference engine, we identified several challenges: Codebase Divergence: Our engine is based on an early fork of vLLM from over a year ago. Although structurally similar, we\u2019ve heavily customized it for DeepSeek models, making it difficult to extend for broader use cases. Infrastructure Dependencies: The engine is tightly coupled with our internal infrastructure, including cluster management tools, making it impractical for public deployment without significant modifications. Limited Maintenance Bandwidth: As a small research team focused on developing better models, we lack bandwidth to maintain a large open-source project. Considering these challenges, we\u2019ve decided to collaborate with existing open-source projects as more sustainable alternatives. Moving forward, we will work closely with existing open-source projects to: Extract Standalone Features: Modularize and contribute reusable components as independent libraries. Share Optimizations: Contribute design improvements and implementation details directly. We are profoundly grateful for the open-source movement - from operating systems and programming languages to machine learning frameworks and inference engines. It\u2019s an honor to contribute to this thriving ecosystem and to see our models and code embraced by the community. Together, let\u2019s push the boundaries of AGI and ensure its benefits serve all of humanity. Note To clarify, this article outlines our approach to open-sourcing of our DeepSeek-Inference-Engine codebase only. Regarding future model releases, we maintain an open and collaborative stance towards both the open-source community and hardware partners. We commit to proactively synchronizing inference-related engineering efforts prior to new model launches, with the goal of enabling the community to achieve state-of-the-art (SOTA) support from Day-0. Our ultimate aim is to foster a synchronized ecosystem where cutting-edge AI capabilities can be seamlessly implemented across diverse hardware platforms upon official model releases.",
        "headline": "DeepSeek Open-Sources Inference Engine",
        "entry_sentence": "DeepSeek has announced the open-sourcing of its internal inference engine to benefit the AI community.",
        "detail": "The team plans to collaborate with existing open-source projects by contributing standalone features and optimizations, despite facing challenges like codebase divergence and maintenance bandwidth.",
        "icon": "\ud83d\udfe3"
    },
    {
        "title": "Meta antitrust trial kicks off in federal court",
        "url": "https://www.axios.com/pro/tech-policy/2025/04/14/ftc-meta-antitrust-trial-kicks-off-in-federal-court",
        "content": "Skip to main content Axios Pro Pro coverage Deals Tracker Reports Corporate subscriptions Subscribe Log In Axios Pro Exclusive Content Meta antitrust trial kicks off in federal court Ashley Gold Apr 14, 2025 facebook (opens in new window) twitter (opens in new window) linkedin (opens in new window) email (opens in new window) Mark Zuckerberg on Jan. 31, 2024 on Capitol Hill. Photo: Tom Williams/CQ-Roll Call, Inc via Getty Images The Federal Trade Commission and Meta will square off in a long-awaited antitrust trial on Monday over the tech giant's past acquisitions of WhatsApp and Instagram. Why it matters: The trial will be a major test of the FTC's ability to take on tech behemoths for allegedly breaking antitrust law and comes as Meta CEO Mark Zuckerberg tries to cozy up to President Trump. The case could result in Meta having to spin off WhatsApp and Instagram. If Meta wins, the company would be vindicated in its longtime argument that the two apps couldn't have thrived without the company's backing and that Meta has plenty of competition in the social networking space. The lawsuit's main question is whether Meta acted illegally in its WhatsApp and Instagram acquisitions, done in 2014 and 2012. Federal judge James Boasberg will hear the case, which was first filed in December 2020 under Trump's first administration. A judge dismissed that original lawsuit in June 2021 for lacking sufficient evidence of Meta's market power. Under Lina Khan, FTC chair under President Biden, the case was re-filed and expanded in August 2021. Boasberg allowed that case to proceed in January 2022, and rejected a bid from Meta last year to have the case dismissed, paving way for this trial. What they're saying: The FTC says Meta has illegally monopolized the market for \"personal social networking services\" through those acquisitions, in a bid to \"neutralize\" its rivals, per legal filings. \"Acquiring these competitive threats has enabled Facebook to sustain its dominance\u2014to the detriment of competition and users\u2014not by competing on the merits, but by avoiding competition,\" the FTC wrote in a filing. Meta could have chosen to compete with then-upstart photo sharing app Instagram in 2012, a senior FTC official said on a call with reporters ahead of the trial, but instead it bought it, and did the same with WhatsApp. The other side: \"The FTC's lawsuit against Meta defies reality. The evidence at trial will show what every 17-year-old in the world knows: Instagram, Facebook and WhatsApp compete with Chinese-owned TikTok, YouTube, X, iMessage and many others,\" Meta spokesperson Chris Sgro said in a statement. \"More than 10 years after the FTC reviewed and cleared our acquisitions, the Commission's action in this case sends the message that no deal is ever truly final.\" \"Regulators should be supporting American innovation, rather than seeking to break up a great American company and further advantaging China on critical issues like AI.\" What we're watching: The case could take eight weeks or more. There'll be a slew of high-profile witnesses, including Zuckerberg. Former COO Sheryl Sandberg, chief technology officer Andrew Bosworth, and WhatsApp and Instagram leadership past and present, will also testify, per court filings. Representatives from Snap, TikTok and Pinterest are expected to testify as well. Our thought bubble: Tech firms have gotten much closer with Trump in his second term. But unless Trump tells the FTC to shut the whole trial down, Meta's overtures may not do the company any good here. facebook (opens in new window) twitter (opens in new window) linkedin (opens in new window) email (opens in new window) Go deeper Sara Fischer 1 hour ago - Business Meta's copycat strategy targeted in court Data: Techmeme; Chart: Axios Visuals Meta has a long history of acquiring or building copycat apps and features that have ultimately failed and shuttered in less than a few years. But the unprecedented success of two of its biggest bets have regulators concerned its tactics are anticompetitive. Why it matters: Faced with a historic antitrust lawsuit, Meta argues its acquisitions of Instagram and WhatsApp weren't meant to stifle smaller competitors, but help it remain relevant to users as the social media landscape evolved. Go deeper (1 min. read) facebook (opens in new window) twitter (opens in new window) linkedin (opens in new window) email (opens in new window) Sareen Habeshian Apr 8, 2025 - Technology Read: Whistleblower alleges Meta undermined U.S. national security Mark Zuckerberg on Jan. 31, 2024, in Washington, D.C. Photo: Alex Wong/Getty Images Meta whistleblower Sarah Wynn-Williams is set to testify before the Senate Judiciary Subcommittee on Crime and Counterterrorism on Wednesday. The big picture: The former global public policy director at Facebook, now Meta, will allege that Facebook cooperated with China's ruling Communist Party, per her opening testimony, as seen by Axios. Go deeper (1 min. read) facebook (opens in new window) twitter (opens in new window) linkedin (opens in new window) email (opens in new window) Sara Fischer 1 hour ago - Business Meta's copycat strategy targeted in court Data: Techmeme; Chart: Axios Visuals Meta has a long history of acquiring or building copycat apps and features that have ultimately failed and shuttered in less than a few years. But the unprecedented success of two of its biggest bets have regulators concerned its tactics are anticompetitive. Why it matters: Faced with a historic antitrust lawsuit, Meta argues its acquisitions of Instagram and WhatsApp weren't meant to stifle smaller competitors, but help it remain relevant to users as the social media landscape evolved. Go deeper (1 min. read) facebook (opens in new window) twitter (opens in new window) linkedin (opens in new window) email (opens in new window) Axios Pro This article is currently free. Request a trial Smarter, faster on what matters. Explore Axios Newsletters About Axios Advertise with us Careers Contact us Newsletters Axios Live Axios Entertainment Axios HQ Privacy policy Terms of use Axios Homepage Copyright Axios Media, 2024",
        "headline": "Meta antitrust trial begins",
        "entry_sentence": "A federal antitrust trial against Meta started on Monday over its acquisitions of WhatsApp and Instagram.",
        "detail": "The Federal Trade Commission claims Meta illegally monopolized the social networking market, while Meta argues the acquisitions were necessary for competition.",
        "icon": "\ud83d\udfe3"
    }
]